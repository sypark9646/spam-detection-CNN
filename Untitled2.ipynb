{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'mxnet'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-86-f8f5dc815a31>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mmxnet\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mgluon\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'mxnet'"
     ]
    }
   ],
   "source": [
    "from keras.utils import to_categorical\n",
    "from keras.preprocessing import sequence\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.models import Model, load_model\n",
    "from keras.layers import Conv1D, GlobalMaxPooling1D, Dropout, Dense, Input, Embedding, MaxPooling1D, Flatten\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "import numpy as np\n",
    "import pickle\n",
    "import pandas as pd \n",
    "from mxnet import gluon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>smishing</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>XXX은행성산XXX팀장입니다.행복한주말되세요</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>오늘도많이웃으시는하루시작하세요XXX은행 진월동VIP라운지 XXX올림</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>안녕하십니까 고객님. XXX은행입니다.금일 납부하셔야 할 금액은 153600원 입니...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>XXX 고객님안녕하세요XXX은행 XXX지점입니다지난 한 해 동안 저희 XXX지점에 ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1월은 새로움이 가득XXX입니다.올 한해 더 많이행복한 한해되시길바랍니다</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  smishing\n",
       "0                           XXX은행성산XXX팀장입니다.행복한주말되세요         0\n",
       "1              오늘도많이웃으시는하루시작하세요XXX은행 진월동VIP라운지 XXX올림         0\n",
       "2  안녕하십니까 고객님. XXX은행입니다.금일 납부하셔야 할 금액은 153600원 입니...         0\n",
       "3  XXX 고객님안녕하세요XXX은행 XXX지점입니다지난 한 해 동안 저희 XXX지점에 ...         0\n",
       "4           1월은 새로움이 가득XXX입니다.올 한해 더 많이행복한 한해되시길바랍니다         0"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the Pandas libraries with alias 'pd' \n",
    "import pandas as pd \n",
    "# Read data from file 'filename.csv' \n",
    "# (in the same directory that your python process is based)\n",
    "# Control delimiters, rows, column names with read_csv (see later) \n",
    "train_df = pd.read_csv('../dacon/data/train.csv', encoding='utf-8') \n",
    "# Preview the first 5 lines of the loaded data \n",
    "train_df.drop(['id'], 1, inplace=True)\n",
    "train_df.drop(['year_month'], 1, inplace=True)\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>smishing</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>XXX은행성산XXX팀장입니다.행복한주말되세요</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>오늘도많이웃으시는하루시작하세요XXX은행 진월동VIP라운지 XXX올림</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>안녕하십니까 고객님. XXX은행입니다.금일 납부하셔야 할 금액은 153600원 입니...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>XXX 고객님안녕하세요XXX은행 XXX지점입니다지난 한 해 동안 저희 XXX지점에 ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1월은 새로움이 가득XXX입니다.올 한해 더 많이행복한 한해되시길바랍니다</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  smishing\n",
       "0                           XXX은행성산XXX팀장입니다.행복한주말되세요         0\n",
       "1              오늘도많이웃으시는하루시작하세요XXX은행 진월동VIP라운지 XXX올림         0\n",
       "2  안녕하십니까 고객님. XXX은행입니다.금일 납부하셔야 할 금액은 153600원 입니...         0\n",
       "3  XXX 고객님안녕하세요XXX은행 XXX지점입니다지난 한 해 동안 저희 XXX지점에 ...         0\n",
       "4           1월은 새로움이 가득XXX입니다.올 한해 더 많이행복한 한해되시길바랍니다         0"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_sample = train_df[train_df['smishing'] == 0].head(100) \n",
    "train_sample = train_sample.append(train_df[train_df['smishing'] == 1].head(100) , ignore_index=True)\n",
    "train_sample.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "train_sample.to_csv(\"training_sample.csv\", mode='w', encoding='utf-8', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#==============================================================================================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>smishing</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>XXX은행성산XXX팀장입니다.행복한주말되세요</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>오늘도많이웃으시는하루시작하세요XXX은행 진월동VIP라운지 XXX올림</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>안녕하십니까 고객님. XXX은행입니다.금일 납부하셔야 할 금액은 153600원 입니...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>XXX 고객님안녕하세요XXX은행 XXX지점입니다지난 한 해 동안 저희 XXX지점에 ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1월은 새로움이 가득XXX입니다.올 한해 더 많이행복한 한해되시길바랍니다</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  smishing\n",
       "0                           XXX은행성산XXX팀장입니다.행복한주말되세요         0\n",
       "1              오늘도많이웃으시는하루시작하세요XXX은행 진월동VIP라운지 XXX올림         0\n",
       "2  안녕하십니까 고객님. XXX은행입니다.금일 납부하셔야 할 금액은 153600원 입니...         0\n",
       "3  XXX 고객님안녕하세요XXX은행 XXX지점입니다지난 한 해 동안 저희 XXX지점에 ...         0\n",
       "4           1월은 새로움이 가득XXX입니다.올 한해 더 많이행복한 한해되시길바랍니다         0"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the Pandas libraries with alias 'pd' \n",
    "import pandas as pd \n",
    "train_df = pd.read_csv('./training_sample.csv', encoding='utf-8') \n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "244\n",
      "3288\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "import kss\n",
    "word_counter = Counter()\n",
    "\n",
    "maxlen=0\n",
    "for i, row in train_df.iterrows(): \n",
    "    wordlen=0\n",
    "    train_text=kss.split_sentences(row['text'])\n",
    "    for sent in train_text:\n",
    "        sent=sent.replace('X', ' ')\n",
    "        word_counter.update(sent.split())\n",
    "        wordlen += len(sent.split())\n",
    "    maxlen=max([maxlen, wordlen])\n",
    "\n",
    "vocab=dict()\n",
    "voca_index=3\n",
    "vocab['PAD']=0\n",
    "vocab['SEN_START']=1\n",
    "vocab['SEN_END']=2\n",
    "for key in word_counter.keys():\n",
    "    vocab[key]=voca_index\n",
    "    voca_index += 1\n",
    "    \n",
    "print(maxlen)\n",
    "print(len(vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>smishing</th>\n",
       "      <th>word2ind</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>XXX은행성산XXX팀장입니다.행복한주말되세요</td>\n",
       "      <td>0</td>\n",
       "      <td>[3, 4, 5]</td>\n",
       "      <td>[1, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>오늘도많이웃으시는하루시작하세요XXX은행 진월동VIP라운지 XXX올림</td>\n",
       "      <td>0</td>\n",
       "      <td>[6, 7, 8, 9]</td>\n",
       "      <td>[1, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>안녕하십니까 고객님. XXX은행입니다.금일 납부하셔야 할 금액은 153600원 입니...</td>\n",
       "      <td>0</td>\n",
       "      <td>[10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 2...</td>\n",
       "      <td>[1, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>XXX 고객님안녕하세요XXX은행 XXX지점입니다지난 한 해 동안 저희 XXX지점에 ...</td>\n",
       "      <td>0</td>\n",
       "      <td>[25, 7, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35...</td>\n",
       "      <td>[1, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1월은 새로움이 가득XXX입니다.올 한해 더 많이행복한 한해되시길바랍니다</td>\n",
       "      <td>0</td>\n",
       "      <td>[59, 60, 61, 18, 62, 63, 64, 65, 66]</td>\n",
       "      <td>[1, 0]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  smishing  \\\n",
       "0                           XXX은행성산XXX팀장입니다.행복한주말되세요         0   \n",
       "1              오늘도많이웃으시는하루시작하세요XXX은행 진월동VIP라운지 XXX올림         0   \n",
       "2  안녕하십니까 고객님. XXX은행입니다.금일 납부하셔야 할 금액은 153600원 입니...         0   \n",
       "3  XXX 고객님안녕하세요XXX은행 XXX지점입니다지난 한 해 동안 저희 XXX지점에 ...         0   \n",
       "4           1월은 새로움이 가득XXX입니다.올 한해 더 많이행복한 한해되시길바랍니다         0   \n",
       "\n",
       "                                            word2ind  labels  \n",
       "0                                          [3, 4, 5]  [1, 0]  \n",
       "1                                       [6, 7, 8, 9]  [1, 0]  \n",
       "2  [10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 2...  [1, 0]  \n",
       "3  [25, 7, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35...  [1, 0]  \n",
       "4               [59, 60, 61, 18, 62, 63, 64, 65, 66]  [1, 0]  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "import kss\n",
    "\n",
    "train_df['word2ind'] = np.nan\n",
    "train_df['word2ind'] = train_df['word2ind'].astype(object) \n",
    "\n",
    "train_df['labels'] = np.nan\n",
    "train_df['labels'] = train_df['word2ind'].astype(object) \n",
    "\n",
    "\n",
    "for i, row in train_df.iterrows(): \n",
    "    msg=kss.split_sentences(row['text'])\n",
    "    words=[]\n",
    "    word2ind=[]\n",
    "    for sent in msg:\n",
    "        sent=sent.replace('X', ' ')\n",
    "        words.extend(sent.split())\n",
    "    \n",
    "    for word in words:\n",
    "        if word in vocab:\n",
    "            word2ind.append(vocab[word])\n",
    "        else:\n",
    "            word2ind.append(0)\n",
    "\n",
    "    #padding maxlen\n",
    "    #a = word2ind\n",
    "    #pad_value = 0\n",
    "    #pad_size = maxlen - len(a)\n",
    "    #word2ind = [*a, *[pad_value] * pad_size]\n",
    "\n",
    "    train_df.at[i, 'word2ind'] = word2ind\n",
    "    \n",
    "    if row['smishing'] == 0: \n",
    "        train_df.at[i, 'labels'] = [1,0]\n",
    "    else:\n",
    "        train_df.at[i, 'labels'] = [0,1]\n",
    "    \n",
    "\n",
    "print(len(train_df))\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word2ind</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[3, 4, 5]</td>\n",
       "      <td>[1, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[6, 7, 8, 9]</td>\n",
       "      <td>[1, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 2...</td>\n",
       "      <td>[1, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[25, 7, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35...</td>\n",
       "      <td>[1, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[59, 60, 61, 18, 62, 63, 64, 65, 66]</td>\n",
       "      <td>[1, 0]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            word2ind  labels\n",
       "0                                          [3, 4, 5]  [1, 0]\n",
       "1                                       [6, 7, 8, 9]  [1, 0]\n",
       "2  [10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 2...  [1, 0]\n",
       "3  [25, 7, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35...  [1, 0]\n",
       "4               [59, 60, 61, 18, 62, 63, 64, 65, 66]  [1, 0]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Make Data\n",
    "train_df.drop(['text'], 1, inplace=True)\n",
    "train_df.drop(['smishing'], 1, inplace=True)\n",
    "print(len(train_df))\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#================================================================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.to_pickle(\"./smishing_training_sample.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#================================================================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_WORDS_IN_SEQ = 244 #\n",
    "EMBED_DIM = 200\n",
    "MODEL_PATH = \"./models/smishing_detect\"\n",
    "\n",
    "import os\n",
    "os.makedirs(os.path.dirname(MODEL_PATH), exist_ok=True)\n",
    "\n",
    "# Load Data\n",
    "\n",
    "#with open(\"smishing_training.pkl\", 'rb') as f:\n",
    "#    word2index, labels = pickle.load(f) #한줄만 읽음\n",
    "\n",
    "data = []\n",
    "labels = []\n",
    "\n",
    "train_df=pd.read_pickle('./smishing_training_sample.pkl')\n",
    "#train_df.head()\n",
    "\n",
    "for i, row in train_df.iterrows():\n",
    "    d = row['word2ind']\n",
    "    l = row['labels']\n",
    "    \n",
    "    d = to_categorical(d)\n",
    "    d = sequence.pad_sequences(d, maxlen=3288, padding='post', value=0)\n",
    "    data.append(d)\n",
    "    labels.append(l)\n",
    "    #print(d, l)\n",
    "    #break\n",
    "\n",
    "data = np.array(data)\n",
    "labels = np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(200,)\n",
      "(200, 244, 3288)\n",
      "(200, 2)\n",
      "Shape of label tensor: (200, 2)\n",
      "x_train (160, 244, 3288)\n",
      "x_test (40, 244, 3288)\n",
      "y_train (160, 2)\n",
      "y_test (40, 2)\n"
     ]
    }
   ],
   "source": [
    "print(data.shape)\n",
    "data = sequence.pad_sequences(data, maxlen=MAX_WORDS_IN_SEQ, padding='post', value=0)\n",
    "print(data.shape)\n",
    "print(labels.shape)\n",
    "#print('Shape of data tensor:', data.shape)\n",
    "print('Shape of label tensor:', labels.shape)\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(data, labels, test_size=0.2)\n",
    "print(\"x_train\", x_train.shape)\n",
    "print(\"x_test\", x_test.shape)\n",
    "print(\"y_train\", y_train.shape)\n",
    "print(\"y_test\", y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(?, 244, 3288)\n",
      "conv_1 (?, 240, 128)\n",
      "conv_1_maxpooling1D (?, 48, 128)\n",
      "conv_2 (?, 44, 128)\n",
      "conv_2_maxpooling1D (?, 8, 128)\n",
      "conv_3 (?, 4, 128)\n",
      "conv_3_maxpooling1D (?, 1, 128)\n",
      "flat (?, ?)\n",
      "flat_dropout (?, ?)\n",
      "dense (?, 128)\n",
      "dense_dropout (?, ?)\n",
      "dense (?, 2)\n",
      "Model: \"model_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_4 (InputLayer)         (None, 244, 3288)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_10 (Conv1D)           (None, 240, 128)          2104448   \n",
      "_________________________________________________________________\n",
      "max_pooling1d_10 (MaxPooling (None, 48, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_11 (Conv1D)           (None, 44, 128)           82048     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_11 (MaxPooling (None, 8, 128)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_12 (Conv1D)           (None, 4, 128)            82048     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_12 (MaxPooling (None, 1, 128)            0         \n",
      "_________________________________________________________________\n",
      "flatten_4 (Flatten)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 2)                 258       \n",
      "=================================================================\n",
      "Total params: 2,285,314\n",
      "Trainable params: 2,285,314\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Building the model\n",
    "input_seq = Input(shape=(MAX_WORDS_IN_SEQ, 3288))#, dtype='int32')\n",
    "print(input_seq.shape)\n",
    "#embed_seq = Embedding(3288, EMBED_DIM, embeddings_initializer='glorot_normal', input_length=MAX_WORDS_IN_SEQ)(input_seq)\n",
    "#print(embed_seq.shape)\n",
    "\n",
    "conv_1 = Conv1D(128, 5, activation='relu')(input_seq)\n",
    "print(\"conv_1\", conv_1.shape)\n",
    "conv_1 = MaxPooling1D(pool_size=5)(conv_1)\n",
    "print(\"conv_1_maxpooling1D\", conv_1.shape)\n",
    "conv_2 = Conv1D(128, 5, activation='relu')(conv_1)\n",
    "print(\"conv_2\", conv_2.shape)\n",
    "conv_2 = MaxPooling1D(pool_size=5)(conv_2)\n",
    "print(\"conv_2_maxpooling1D\", conv_2.shape)\n",
    "conv_3 = Conv1D(128, 5, activation='relu')(conv_2)\n",
    "print(\"conv_3\", conv_3.shape)\n",
    "conv_3 = MaxPooling1D(pool_size=3)(conv_3) #\n",
    "print(\"conv_3_maxpooling1D\", conv_3.shape)\n",
    "flat = Flatten()(conv_3)\n",
    "print(\"flat\", flat.shape)\n",
    "flat = Dropout(0.25)(flat)\n",
    "print(\"flat_dropout\", flat.shape)\n",
    "fc1 = Dense(128, activation='relu')(flat)\n",
    "print(\"dense\", fc1.shape)\n",
    "dense_1 = Dropout(0.25)(flat)\n",
    "print(\"dense_dropout\", dense_1.shape)\n",
    "fc2 = Dense(2, activation='softmax')(fc1)\n",
    "print(\"dense\", fc2.shape)\n",
    "\n",
    "model = Model(input_seq, fc2)\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['acc'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/2\n",
      "160/160 [==============================] - 1s 6ms/step - loss: 0.6846 - acc: 0.4313 - val_loss: 0.5906 - val_acc: 0.5500\n",
      "Epoch 2/2\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 0.5986 - acc: 0.5125 - val_loss: 0.4597 - val_acc: 0.7750\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "model.fit(\n",
    "    x_train,\n",
    "    y_train,\n",
    "    batch_size=128,\n",
    "    epochs=2,\n",
    "    callbacks=[ModelCheckpoint(MODEL_PATH, save_best_only=True)],\n",
    "    validation_data=(x_test, y_test)\n",
    ")\n",
    "\n",
    "model.save(MODEL_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_4 (InputLayer)         (None, 244, 3288)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_10 (Conv1D)           (None, 240, 128)          2104448   \n",
      "_________________________________________________________________\n",
      "max_pooling1d_10 (MaxPooling (None, 48, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_11 (Conv1D)           (None, 44, 128)           82048     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_11 (MaxPooling (None, 8, 128)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_12 (Conv1D)           (None, 4, 128)            82048     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_12 (MaxPooling (None, 1, 128)            0         \n",
      "_________________________________________________________________\n",
      "flatten_4 (Flatten)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 2)                 258       \n",
      "=================================================================\n",
      "Total params: 2,285,314\n",
      "Trainable params: 2,285,314\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'gluon' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-42-79208f07aff6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mclass\u001b[0m \u001b[0mCnnClassifierModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgluon\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mHybridBlock\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mCnnClassifierModel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgluon\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mConv1D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'gluon' is not defined"
     ]
    }
   ],
   "source": [
    "class CnnClassifierModel(gluon.HybridBlock):\n",
    "    def __init__(self, **kwargs):\n",
    "        super(CnnClassifierModel, self).__init__(**kwargs)\n",
    "        with self.name_scope():\n",
    "            self.conv1 = gluon.nn.Conv1D()\n",
    "\n",
    "    def hybrid_forward(self, F, x, *args, **kwargs):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/5\n",
      "160/160 [==============================] - 1s 6ms/step - loss: 0.2687 - acc: 0.9875 - val_loss: 0.2093 - val_acc: 1.0000\n",
      "Epoch 2/5\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 0.2332 - acc: 0.9750 - val_loss: 0.1716 - val_acc: 1.0000\n",
      "Epoch 3/5\n",
      "160/160 [==============================] - 1s 5ms/step - loss: 0.1741 - acc: 0.9812 - val_loss: 0.1324 - val_acc: 1.0000\n",
      "Epoch 4/5\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 0.1186 - acc: 0.9875 - val_loss: 0.0958 - val_acc: 1.0000\n",
      "Epoch 5/5\n",
      "160/160 [==============================] - 1s 5ms/step - loss: 0.0736 - acc: 0.9875 - val_loss: 0.0637 - val_acc: 1.0000\n"
     ]
    }
   ],
   "source": [
    "model = load_model(MODEL_PATH)\n",
    "model.fit(\n",
    "    x_train,\n",
    "    y_train,\n",
    "    batch_size=128,\n",
    "    epochs=5,\n",
    "    callbacks=[ModelCheckpoint(MODEL_PATH, save_best_only=True)],\n",
    "    validation_data=[x_test, y_test]\n",
    ")\n",
    "\n",
    "model.save(MODEL_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#====================================================================================================================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Model' object has no attribute 'load'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-88-8320519a9d24>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mMODEL_PATH\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'Model' object has no attribute 'load'"
     ]
    }
   ],
   "source": [
    "model.load(MODEL_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 244, 3288)\n"
     ]
    }
   ],
   "source": [
    "test_text = \"믿고 거래해주셔서 진심으로 감사합니다.행복한하루되세요XXX당진XXX올림\"\n",
    "msg=kss.split_sentences(test_text)\n",
    "words=[]\n",
    "word2ind=[]\n",
    "for sent in msg:\n",
    "    sent=sent.replace('X', ' ')\n",
    "    words.extend(sent.split())\n",
    "for word in words:\n",
    "    if word in vocab:\n",
    "        word2ind.append(vocab[word])\n",
    "    else:\n",
    "        word2ind.append(0)\n",
    "\n",
    "data = []\n",
    "for d in word2ind:\n",
    "    d = to_categorical(d)\n",
    "    #print(d)\n",
    "    N = 3288\n",
    "    a = d\n",
    "    pad_value = 0\n",
    "    pad_size = N - len(a)\n",
    "    d = [*a, *[pad_value] * pad_size]\n",
    "    data.append(d)\n",
    "    #print(len(d))\n",
    "for i in range(244-len(data)):\n",
    "    d = [0 for i in range(3288)]\n",
    "    data.append(d)\n",
    "    #print(len(d))\n",
    "\n",
    "\n",
    "data = [data]\n",
    "data = np.array(data)\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.86931634 0.13068369]]\n",
      "0.86931634\n"
     ]
    }
   ],
   "source": [
    "prediction = model.predict({'input_4': data })\n",
    "print(prediction)\n",
    "\n",
    "if prediction[0][0]>prediction[0][1]:\n",
    "    print(0)\n",
    "else:\n",
    "    print(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
